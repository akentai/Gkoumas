{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sloth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "from scipy.io.wavfile import write\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "from RealtimeSTT import AudioToTextRecorder\n",
    "from enum import Enum\n",
    "from playsound import playsound\n",
    "from faster_whisper import WhisperModel\n",
    "from google.cloud import speech\n",
    "\n",
    "import speech_recognition as sr\n",
    "import sounddevice as sd\n",
    "import keyboard\n",
    "import whisper\n",
    "import pyttsx3\n",
    "import openai\n",
    "import os\n",
    "from elevenlabs import generate, play, Voice, VoiceSettings, save, set_api_key\n",
    "import warnings \n",
    "import ffmpeg\n",
    "from gtts import gTTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_api_key(\"dcf30be2a174754257e04abcc8d98c64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO LIST\n",
    "## condition start\n",
    "## condition stop\n",
    "## wrapper around creating wav file for whisper\n",
    "## add gpt response\n",
    "## add TTS\n",
    "## continuous speech transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"f1fa3bba2e8543639d7b14c8e5beb91f\"\n",
    "transcriber = aai.Transcriber()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transcription\n",
    "# Whisper\n",
    "model    = whisper.load_model(\"tiny\")\n",
    "# Faster-Whisper\n",
    "fw_model = WhisperModel(\"tiny.en\", device=\"cpu\", compute_type=\"default\", cpu_threads=16)\n",
    "\n",
    "## Prompt\n",
    "# GPT4ALL\n",
    "llm_model   = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")\n",
    "# OpenAI API\n",
    "client      = OpenAI(api_key=\"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\");\n",
    "# EDGEGPT\n",
    "\n",
    "## Text to Speech\n",
    "engine      = pyttsx3.init()\n",
    "\n",
    "## Record\n",
    "# using sounddevice\n",
    "# using speech_recognition module\n",
    "# microphone  = sr.Microphone() \n",
    "# recognizer  = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recording_on_key():\n",
    "    print(\"Press the space button and start speaking...\")\n",
    "    keyboard.wait(\"space\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_speech():\n",
    "    \n",
    "    audio_file = \"\";\n",
    "    \n",
    "    start_recording_on_key()\n",
    "    \n",
    "    # Sampling frequency\n",
    "    freq = 44100;\n",
    "    # Recording duration\n",
    "    duration = 5;\n",
    "    \n",
    "    # Start recorder with the given values of \n",
    "    # duration and sample frequency\n",
    "    recording = sd.rec(int(duration * freq), \n",
    "                    samplerate=freq, channels=2)\n",
    "\n",
    "    # Record audio for the given number of seconds\n",
    "    sd.wait();\n",
    "    \n",
    "    # This will convert the NumPy array to an audio\n",
    "    # file with the given sampling frequency\n",
    "    write(\"recording0.wav\", freq, recording)\n",
    "    \n",
    "    print(\"Recording complete\")\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recorder \u001b[38;5;241m=\u001b[39m \u001b[43mAudioToTextRecorder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspinner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtiny.en\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sloth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\RealtimeSTT\\audio_recorder.py:502\u001b[0m, in \u001b[0;36mAudioToTextRecorder.__init__\u001b[1;34m(self, model, language, compute_type, input_device_index, gpu_device_index, on_recording_start, on_recording_stop, on_transcription_start, ensure_sentence_starting_uppercase, ensure_sentence_ends_with_period, use_microphone, spinner, level, enable_realtime_transcription, realtime_model_type, realtime_processing_pause, on_realtime_transcription_update, on_realtime_transcription_stabilized, silero_sensitivity, silero_use_onnx, webrtc_sensitivity, post_speech_silence_duration, min_length_of_recording, min_gap_between_recordings, pre_recording_buffer_duration, on_vad_detect_start, on_vad_detect_stop, wake_words, wake_words_sensitivity, wake_word_activation_delay, wake_word_timeout, on_wakeword_detected, on_wakeword_timeout, on_wakeword_detection_start, on_wakeword_detection_end)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# Wait for transcription models to start\u001b[39;00m\n\u001b[0;32m    501\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaiting for main transcription model to start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_transcription_ready_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain transcription model ready\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    505\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRealtimeSTT initialization completed successfully\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sloth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\synchronize.py:356\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Sloth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\synchronize.py:268\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# wait for notification or timeout\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_semaphore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# indicate that this thread has woken\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_woken_count\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recorder = AudioToTextRecorder(spinner=False, model=\"tiny.en\", language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_and_transcribe():\n",
    "    \n",
    "    start_recording_on_key()\n",
    "    text_data = recorder.text()\n",
    "    \n",
    "    print(text_data)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper():\n",
    "    \n",
    "    audio_file   = \"recording0.wav\";\n",
    "    trans_object = model.transcribe(audio_file, language=\"en\", fp16=False);\n",
    "    text_data    = trans_object[\"text\"]\n",
    "    \n",
    "    print(text_data)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_faster_whisper():\n",
    "    \n",
    "    audio_file     = \"recording0.wav\";\n",
    "    text_data      = \"\"\n",
    "    segments, info = fw_model.transcribe(audio_file, language='en')\n",
    "    \n",
    "    for segment in segments:\n",
    "        text_data += segment.text\n",
    "        print(segment.text, end=\"\")\n",
    "        \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_whisper_api():\n",
    "\n",
    "    audio_file = open(\"recording0.wav\", \"rb\")\n",
    "    text_data  = \"\"\n",
    "       \n",
    "    text_data  = client.audio.transcriptions.create(\n",
    "        file   = audio_file,\n",
    "        model  = 'whisper-1',\n",
    "        response_format = 'text'\n",
    "    )\n",
    "        \n",
    "    print(text_data)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_with_assemblyai():\n",
    "    \n",
    "    audio_file = open(\"recording0.wav\", \"rb\")\n",
    "    text_data  = \"\"\n",
    "    \n",
    "    transcript = transcriber.transcribe(\"recording0.wav\")\n",
    "    text_data  = transcript.text\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What books would you suggest to a five year old child?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_with_assemblyai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What books would you suggest to a 5-year-old child?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file     = open(\"recording0.wav\", \"rb\")\n",
    "    \n",
    "trans_obj  = client.audio.transcriptions.create(\n",
    "    file   = audio_file,\n",
    "    model  = 'whisper-1',\n",
    "    response_format = 'text'\n",
    ")\n",
    "\n",
    "print(trans_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What books would you suggest to a five-year-old child?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' What books would you suggest to a five-year-old child?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_with_faster_whisper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_speech(stt_engine):\n",
    "    \n",
    "    text_data = \"\"\n",
    "    if stt_engine == 'whisper':\n",
    "        text_data = transcribe_with_whisper()\n",
    "    \n",
    "    elif stt_engine == 'faster_whisper':\n",
    "        text_data = transcribe_with_faster_whisper()\n",
    "    \n",
    "    elif stt_engine == 'whisper_api':\n",
    "        text_data = transcribe_with_whisper_api()\n",
    "                \n",
    "    return text_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_pyttsx3(response):\n",
    "    \n",
    "    engine.say(response)\n",
    "    engine.runAndWait()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_gtts(response):\n",
    "    \n",
    "    # Initialize gTTS with the text to convert\n",
    "    audio_response = gTTS(response)\n",
    "    # Save the audio file to a temporary file\n",
    "    audio_response.save(\"gTTS_response.mp3\")\n",
    "    # Play the audio file\n",
    "    playsound(\"gTTS_response.mp3\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_elevenlabs(response):\n",
    "    \n",
    "    audio_response = generate(\n",
    "                        text  = response,\n",
    "                        voice = \"EXAVITQu4vr4xnSDxMaL\",\n",
    "                        model = \"eleven_monolingual_v1\"\n",
    "    )\n",
    "    save(audio_response, \"elevenlabs_response.mp3\")\n",
    "    playsound(\"elevenlabs_response.mp3\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(response, tts_engine):\n",
    "    \n",
    "    if tts_engine == 'pyttsx3':\n",
    "        speak_pyttsx3(response)\n",
    "    \n",
    "    elif tts_engine == 'gTTS':\n",
    "        speak_gtts(response)\n",
    "    \n",
    "    elif tts_engine == 'elevenlabs':\n",
    "        speak_elevenlabs(response)\n",
    "        \n",
    "    else:\n",
    "        warnings.warn(\"Warning Message: No TTS Engine Selected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_engine = Enum('prompt_engine', ['gpt4all', 'openai_api'])\n",
    "stt_engine    = Enum('tts_engine',    ['whisper', 'faster_whisper'])\n",
    "tts_engine    = Enum('stt_engine',    ['pyttsx3', 'gTTS', 'elevenlabs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gpt_openai_api(text):\n",
    "    \n",
    "    tokens = \"\"\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a voice assistant for children. You are brief.\"},\n",
    "    {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    print(completion.choices[0].message.content)\n",
    "    return (completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gpt4all(text, streaming_prompt=True):\n",
    "    \n",
    "    tokens = \"\"\n",
    "    \n",
    "    #Streaming\n",
    "    if streaming_prompt:\n",
    "        for token in llm_model.generate(text, max_tokens=100, streaming=True):\n",
    "            tokens += token;\n",
    "            print(token, end=\"\");\n",
    "            \n",
    "    #One-shot\n",
    "    else:\n",
    "        tokens = llm_model.generate(text, max_tokens=100);\n",
    "        print(tokens);\n",
    "        return \n",
    "    \n",
    "    return tokens;      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gpt(text, prompt_engine):\n",
    "    \n",
    "    if prompt_engine == 'gpt4all':\n",
    "        response = prompt_gpt4all(text)\n",
    "    \n",
    "    elif prompt_engine == 'openai_api':\n",
    "        response = prompt_gpt_openai_api(text)\n",
    "    \n",
    "    else:\n",
    "        response = prompt_gpt4all(text)\n",
    "\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What books would you suggest with five year old child?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #record_speech();    \n",
    "    text     = transcribe_speech(stt_engine='whisper')\n",
    "    response = prompt_gpt(text, prompt_engine='gpt4all')\n",
    "    speak(response, tts_engine='gTTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstt_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhisper_api\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m, in \u001b[0;36mtranscribe_speech\u001b[1;34m(stt_engine)\u001b[0m\n\u001b[0;32m      8\u001b[0m     text_data \u001b[38;5;241m=\u001b[39m transcribe_with_faster_whisper()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stt_engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhisper_api\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     text_data \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_with_whisper_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_data\n",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m, in \u001b[0;36mtranscribe_with_whisper_api\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m audio_file     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecording0.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m trans_obj  \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mtranscriptions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      6\u001b[0m     file   \u001b[38;5;241m=\u001b[39m audio_file,\n\u001b[0;32m      7\u001b[0m     model  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhisper-1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     response_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m text_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrans_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_data)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_data\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "text = transcribe_speech(stt_engine='whisper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press the space button and start speaking...\n",
      "Suggest me a book from field or just a Yaskie.\n",
      "I recommend the book \"Where the Sidewalk Ends\" by Shel Silverstein. It's a collection of funny and imaginative poems that children usually enjoy.\n",
      "Press the space button and start speaking...\n",
      "Can you briefly mention what was the story of Final Front?\n",
      "\"Final Front\" is a sci-fi adventure story about a group of young scientists who embark on a mission to explore a distant planet for signs of alien life. Along the way, they encounter various challenges and must work together to overcome them.\n",
      "Press the space button and start speaking...\n",
      "Hmm.\n",
      "Hello! How can I help you today?\n",
      "Press the space button and start speaking...\n",
      "Who was Steve Jobs?\n",
      "Steve Jobs was a co-founder of Apple Inc. and known for his work in revolutionizing the technology industry with products like the iPhone and iPad.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    text        = record_and_transcribe();\n",
    "    response    = prompt_gpt(text, prompt_engine='gpt4all');\n",
    "    speak(response, tts_engine='elevenlabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What books would you suggest to a five-year-old child?\n"
     ]
    }
   ],
   "source": [
    "audio_file   = \"recording0.wav\"\n",
    "trans_object = model.transcribe(audio_file, language=\"en\", fp16=False)\n",
    "text_data    = trans_object[\"text\"]\n",
    "\n",
    "print(text_data)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eMascot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
